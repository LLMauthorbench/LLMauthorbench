 # I Know Which LLM Wrote Your Code Last Summer:  LLM generated Code Stylometry for Authorship Attribution

## Description

**LLM-AuthorBench** is a benchmark for authorship attribution of C code generated by large language models (LLMs). As LLM-generated code becomes more common in production and open-source settings, identifying which model produced a given snippet is increasingly important.

This repository provides a dataset of 32,000 compilable C programs generated by eight state-of-the-art LLMs across diverse programming tasks.
The Google Colab code for training and evaluating both traditional ML classifiers and fine-tuned transformer models (e.g., BERT, CodeBERT, Longformer, and LoRA-adapted Qwen2-1.5B) is available in this repository to support further research.

Key results:

**97% accuracy** distinguishing GPT-4.1 vs GPT-4o (DeBERTa-v3, binary classification).

**95% accuracy in 5-way attribution** across Gemini 2.5-Flash, Claude 3.5, GPT-4.1, Llama 3.1, and Deepseek-V3.

 
 ## Framework



<img width="1636" alt="Framework" src="https://github.com/user-attachments/assets/29be292e-d709-4b1d-9e1c-af88d7e5d489" />
